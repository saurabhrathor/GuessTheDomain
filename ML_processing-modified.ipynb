{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the processed_data from txt file\n",
    "input_data = np.loadtxt('in_train.txt', dtype=float)\n",
    "output_data = np.loadtxt('out_train.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53447, 5)\n"
     ]
    }
   ],
   "source": [
    "in_data = input_data[:, :5]\n",
    "print(in_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53447, 1)\n"
     ]
    }
   ],
   "source": [
    "out_data = output_data.argmax(axis=1).reshape(-1,1)\n",
    "print(out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53447, 6)\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data \n",
    "final_data = np.concatenate((in_data, out_data), axis = 1)  # merging the input n expected output\n",
    "print(final_data.shape)\n",
    "np.random.shuffle(final_data)  # shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data[:, :5]\n",
    "Y = final_data[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53447, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35809, 5)\n",
      "(17638, 5)\n",
      "(35809, 1)\n",
      "(17638, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eratsau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n",
    "clf_rand = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf_rand = clf_rand.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_rand = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 6. 4. ... 3. 4. 7.] [7. 6. 4. ... 3. 4. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred, y_pred_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 939, 1559, 1481,  430, 2549, 5850, 1619, 2649,  562],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9754224751061807\n",
      "0.9754224751061807\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(f1_score(y_test, y_pred_rand, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv('test_nvPHrOx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data= testing_data['Url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_list(input):\n",
    "    output = []\n",
    "    for i in input:\n",
    "        text = re.sub(r\"http://\", \"\", i)\n",
    "        text = re.sub(r\"https://\", \"\", text)\n",
    "        #print(output)\n",
    "        output.append(text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data_pro = clean_list(url_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.isrctn.com/ISRCTN57801413',\n",
       " 'www.clinicaltrialsregister.eu/ctr-search/trial/2006-006214-16/GB',\n",
       " 'www.clinicaltrialsregister.eu/ctr-search/trial/2006-004265-34/LT',\n",
       " 'www.clinicaltrialsregister.eu/ctr-search/trial/2010-022183-12/IT']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_data_pro[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eratsau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text, sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocab(field):\n",
    "    #not_found = 'nan'\n",
    "    vocab = []\n",
    "    for line in field:\n",
    "        for i in line.split('/'):\n",
    "            if i not in vocab:\n",
    "                vocab.append(i)\n",
    "    return vocab \n",
    " \n",
    "# generating seq IDs for words in vocabulary\n",
    "def genSeqNo(vocabulary):\n",
    "    i=1.0\n",
    "    vocab_seq = {}\n",
    "    for word in vocabulary:\n",
    "        if word not in vocab_seq:\n",
    "            vocab_seq[word] = i\n",
    "            i = i+1\n",
    "    return vocab_seq\n",
    "\n",
    "# function to replace words with its uniq seq ID\n",
    "def word2Seq(data):\n",
    "    result_seq = []\n",
    "    #max_seq = list(t_vocab_seq.items())[-1][1]\n",
    "    seq_len = []\n",
    "    for line in data:        \n",
    "        seq = []\n",
    "        curr_len = 0\n",
    "        for word in line.split('/'):\n",
    "            curr_len = curr_len + 1\n",
    "            if word in t_vocab_seq:\n",
    "                seq.append(t_vocab_seq[word])\n",
    "            else:\n",
    "                seq.append(0)\n",
    "        result_seq.append(seq)    # to append seqID of line\n",
    "        seq_len.append(curr_len)  # to find and append length of line\n",
    "    return result_seq, seq_len\n",
    "\n",
    "def seqNormalize(seq, data):\n",
    "    norm_seq = []\n",
    "    max_seq = max(seq.values())\n",
    "    norm_seq[:] = [[ele / max_seq for ele in sub] for sub in data]\n",
    "    return norm_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_vocab = createVocab(url_data_pro)   # creating vocabulary \n",
    "t_vocab_seq = genSeqNo(url_vocab)       # generating seqID for each word in vocab\n",
    "url_seq, seqn_len = word2Seq(url_data_pro)    # replacing word with seqID and a list of each line_length\n",
    "url_seq_norm = seqNormalize(t_vocab_seq, url_seq)    # normalizing the seqn IDs between 0 n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0],\n",
       " [3.0, 4.0, 5.0, 6.0, 7.0],\n",
       " [3.0, 4.0, 5.0, 8.0, 9.0],\n",
       " [3.0, 4.0, 5.0, 10.0, 11.0]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_seq[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-55f17dbf9f73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# plotting frequency distribution of SeqnIDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url_seq' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plotting frequency distribution of SeqnIDs\n",
    "plt.hist([url_seq])\n",
    "plt.xticks(range(15))\n",
    "plt.show()\n",
    "# as observed from histogram, taking max_seqn_len as 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding seqn to max_seqn_length\n",
    "#url_seq_pad = sequence.pad_sequences(url_seq_norm, maxlen = max_seq_len, dtype='float32', padding='post')\n",
    "url_seq_pad = sequence.pad_sequences(url_seq, maxlen = 3, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_testing = clf.predict(url_seq_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25787,)\n"
     ]
    }
   ],
   "source": [
    "pred_testing[:4]\n",
    "print(pred_testing.shape)\n",
    "test_prediction = np.array(pred_testing, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "input_data = pd.read_csv('train.csv')\n",
    "label = np.array(input_data['Tag'])\n",
    "\n",
    "# one-hot encoding via sklearn\n",
    "#https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eratsau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "label_decoded = np.array(label_encoder.inverse_transform(test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_decoded[:4])\n",
    "#print(label_decodede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "webid = np.array(testing_data['Webpage_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25787,)\n",
      "(25787,)\n"
     ]
    }
   ],
   "source": [
    "print(webid.shape)\n",
    "print(label_decoded.shape)\n",
    "w = webid.reshape(-1,1)\n",
    "l = label_decoded.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = np.concatenate((w, l),axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 'news'],\n",
       "       [32, 'news'],\n",
       "       [33, 'news'],\n",
       "       [34, 'news']], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('final_output.txt', final_output, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [13,1,5]\n",
    "n = [1,6,3,5,4]\n",
    "\n",
    "x = [a + b for a, b in zip(m, n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"\"\n",
    "s2 = \"testing\"\n",
    "s3 = \"123\"\n",
    "result = s1 or s2 or s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
